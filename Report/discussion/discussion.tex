\chapter{Discussion} \label{ch:discussion}
Throughout this report different statistical concepts have been studied in conjunction with decision support systems. The different concepts that have been studied, all provide different aspects of decision support systems, and should all be considered when the need of studying large datasets is present.

In chapter \textbf{\ref{ch:regression} Linear Regression}, the theory behind multiple linear regression and logistic regression is studied. The linear regression result in a linear model and logistic regression result in a binary classifier. The laboratory exercise show that even though it is easy and simple to make linear models, some times it is insufficient and more complex models are needed.

Chapter \textbf{\ref{ch:linearDiscriminantAnalysis} Discriminant Analysis}, elaborate on the concepts of linear and quadratic discriminant analysis. LDA result in a linear model like the linear regression. QDA result in a quadratic model, used where the linear model is insufficient.

In chapter \textbf{\ref{ch:resamplingMethods} Resampling Methods}, the concepts of Bias Variance trade off, Cross Validation and Bootstrap are covered. Every decision will have pros and cons, knowledge of the bias variance trade off is needed. Validation of models can be done with different versions of the mathematically simple, yet very effective, cross validation method. In cases where there is limited amounts of data, Bootstrap can be an effective way of creating additional data for testing and training of models, however some drawbacks can occur, when creating more test data.

In chapter \textbf{\ref{ch:subsetSelection} Subset Selection}, different methods of subset selection are studied together with different validation methods. Best subset selection is able to find the most effective predictors at a given time to predict a model but at the cost of computations. Forward or backwards stepwise selection gives sufficiently good predictors but without the high computation costs. The chapter end up studying different validation methods of the predictors, Mallow's Cp, AIC, BIC and Adjusted R-squared, comparing them to the cross validation at the end.

In chapter \textbf{\ref{ch:shrinkageMethods} Shrinkage Methods}, the two shrinkage methods, Lasso and Ridge regression are studied and compared. The Lasso regression uses the L1 norm to shrink the data, shrinking and removing predictors. The Ridge regression uses the L2 norm to shrink the data, shrinking predictors towards zero without actively removing them. Shrinkage methods compared to subset selections are less computational heavy and can easily be sufficient.

In chapter \textbf{\ref{ch:clusteringMethods} Clustering Methods}, the concept of clustering data is studied. Data can be in a variety of undefined clusters when observed, to compute and find clusters clustering methods are utilized. In the report k-means clustering and hierarchical clustering are elaborated upon. Both methods having their pros and cons.

All of the above concepts all matter when talking about decision support systems. It is not simple to use one of the concepts without also using some of the others, they all reference to different decisions that is to be made.

This report gives a good overview of concepts of decision support systems, and in a world with unlimited amounts of data, computational power can become problematic factor because of the time consumption. Having the knowledge of how to improve decision support systems, with the knowledge of the data being studied, can greatly improve intelligent systems, and further develop machine learning as a tool.


%Key points:

%We have learned various techniques that can be applied to various data set to both enable us to provide .... various good stuffs.

%Of particular interest to the authors were the techniques surrounding the topics of ...?

%Why did we do this?


